{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_toc import extract_toc\n",
    "from annotate_toc import annotate_toc_against_sumamry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../../../Dataset/FNS2022/English/training/'\n",
    "valid_dir = '../../../Dataset/FNS2022/English/validation/'\n",
    "test_dir = '../../../Dataset/FNS2022/English/test/'\n",
    "out = 'out'\n",
    "annual_reports_dir = \"annual_reports\"\n",
    "gold_summary_dir = \"gold_summaries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract TOC in Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_toc_pos_file_name = 'train_toc_loc.pkl'\n",
    "out_toc_len_file_name = 'train_toc_len.pkl'\n",
    "out_dir_path = os.path.join(train_dir, out)\n",
    "out_annotated_file_name = 'train_annotated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "Processing File Number:  0\n",
      "Processing File Number:  300\n",
      "TOC not found in:  13349.txt\n",
      "Processing File Number:  600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Work\\AI_India_Research\\FNP-2022\\GitRepo\\FNP2022\\1_Annotated_Dataset_Prep\\extract_toc.py\", line 554, in extract_toc\n",
      "    if abs(start_pos - pages[0]) > 100:\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC not found in:  16836.txt\n",
      "TOC not found in:  16837.txt\n",
      "Processing File Number:  900\n",
      "TOC not found in:  18615.txt\n",
      "Processing File Number:  1200\n",
      "Processing File Number:  1500\n",
      "Processing File Number:  1800\n",
      "Processing File Number:  2100\n",
      "Processing File Number:  2400\n",
      "TOC not found in:  7386.txt\n",
      "Processing File Number:  2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Work\\AI_India_Research\\FNP-2022\\GitRepo\\FNP2022\\1_Annotated_Dataset_Prep\\extract_toc.py\", line 552, in extract_toc\n",
      "    pages = weak_search(toc, pages_search_by_title, tmp_file)\n",
      "TypeError: weak_search() missing 1 required positional argument: 'start_pos'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Work\\AI_India_Research\\FNP-2022\\GitRepo\\FNP2022\\1_Annotated_Dataset_Prep\\extract_toc.py\", line 552, in extract_toc\n",
      "    pages = weak_search(toc, pages_search_by_title, tmp_file)\n",
      "TypeError: weak_search() missing 1 required positional argument: 'start_pos'\n"
     ]
    }
   ],
   "source": [
    "file_toc_loc, file_toc_len = extract_toc(train_dir, annual_reports_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(out_dir_path)\n",
    "\n",
    "with open(os.path.join(out_dir_path, out_toc_pos_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(file_toc_loc, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.path.join(out_dir_path, out_toc_len_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(file_toc_len, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_toc_loc.pkl  loaded\n",
      "train_toc_len.pkl  loaded\n",
      "Total sections to be processed:  67893\n",
      "Building dataframe\n",
      "processing file num  0\n",
      "processing file num  300\n",
      "processing file num  600\n",
      "processing file num  900\n",
      "processing file num  1200\n",
      "processing file num  1500\n",
      "processing file num  1800\n",
      "processing file num  2100\n",
      "processing file num  2400\n",
      "processing file num  2700\n",
      "Annotated dataset shape (67893, 5)\n"
     ]
    }
   ],
   "source": [
    "toc_annotated_df = annotate_toc_against_sumamry(train_dir, gold_summary_dir, os.path.join(train_dir, out), out_toc_pos_file_name, out_toc_len_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_annotated_df.to_csv(os.path.join(out_dir_path, out_annotated_file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract TOC in Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_toc_pos_file_name = 'valid_toc_loc.pkl'\n",
    "out_toc_len_file_name = 'valid_toc_len.pkl'\n",
    "out_dir_path = os.path.join(valid_dir, out)\n",
    "out_annotated_file_name = 'valid_annotated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n",
      "Processing File Number:  0\n",
      "TOC not found in:  31014.txt\n",
      "Processing File Number:  300\n"
     ]
    }
   ],
   "source": [
    "valid_file_toc_loc, valid_file_toc_len = extract_toc(valid_dir, annual_reports_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(out_dir_path)\n",
    "\n",
    "with open(os.path.join(out_dir_path, out_toc_pos_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(valid_file_toc_loc, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.path.join(out_dir_path, out_toc_len_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(valid_file_toc_len, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_toc_loc.pkl  loaded\n",
      "valid_toc_len.pkl  loaded\n",
      "Total sections to be processed:  9597\n",
      "Building dataframe\n",
      "processing file num  0\n",
      "processing file num  300\n",
      "Annotated dataset shape (9597, 5)\n"
     ]
    }
   ],
   "source": [
    "toc_annotated_df = annotate_toc_against_sumamry(valid_dir, gold_summary_dir, os.path.join(valid_dir, out), out_toc_pos_file_name, out_toc_len_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_annotated_df.to_csv(os.path.join(out_dir_path, out_annotated_file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract TOC in Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_toc_pos_file_name = 'test_toc_loc.pkl'\n",
    "out_toc_len_file_name = 'test_toc_len.pkl'\n",
    "out_dir_path = os.path.join(test_dir, out)\n",
    "out_annotated_file_name = 'test_annotated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n",
      "Processing File Number:  0\n",
      "TOC not found in:  31014.txt\n",
      "Processing File Number:  100\n",
      "Processing File Number:  200\n",
      "Processing File Number:  300\n"
     ]
    }
   ],
   "source": [
    "test_file_toc_loc, test_file_toc_len = extract_toc(test_dir, annual_reports_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_toc_loc.pkl  loaded\n",
      "valid_toc_len.pkl  loaded\n",
      "Total sections to be processed:  9597\n",
      "Building dataframe\n",
      "processing file num  0\n",
      "processing file num  50\n",
      "processing file num  100\n",
      "processing file num  150\n",
      "processing file num  200\n",
      "processing file num  250\n",
      "processing file num  300\n",
      "processing file num  350\n",
      "Annotated dataset shape (9597, 5)\n"
     ]
    }
   ],
   "source": [
    "toc_annotated_df = annotate_toc_against_sumamry(valid_dir, gold_summary_dir, os.path.join(valid_dir, out), out_toc_pos_file_name, out_toc_len_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_annotated_df.to_csv(os.path.join(out_dir_path, out_annotated_file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
