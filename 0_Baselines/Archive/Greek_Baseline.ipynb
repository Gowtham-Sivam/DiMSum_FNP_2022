{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dace1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "# Load Packages\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d2d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = '../../../Dataset/FNS2022/Greek/validation/'\n",
    "annual_reports_dir = \"annual_reports\"\n",
    "gold_summary_dir = \"gold_summaries\"\n",
    "lex_rank_dir = 'lex_rank_summary_el'\n",
    "text_rank_dir = 'text_rank_summary_el'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d972213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(text_rank_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0786afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File Number:  0 276.txt\n",
      "1390\n",
      "Processing File Number:  1 114.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zm/pvdw66f97v9cmg7tw8wq8jr40000gn/T/ipykernel_41007/3790473600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Summarize using sumy TextRank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msummarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextRankSummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtext_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sumy/summarizers/text_rank.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, document, sentences_count)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_best_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sumy/summarizers/text_rank.py\u001b[0m in \u001b[0;36mrate_sentences\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrate_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sumy/summarizers/text_rank.py\u001b[0m in \u001b[0;36m_create_matrix\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_as_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rate_sentences_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_as_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_file = 0\n",
    "\n",
    "for file in os.listdir(os.path.join(dir_, annual_reports_dir)):\n",
    "    try:\n",
    "        print(\"Processing File Number: \", num_file, file)\n",
    "        num_file = num_file +1 \n",
    "        file_id = file.split('.')[0]\n",
    "        \n",
    "        tmp_file = []\n",
    "        with open(os.path.join(dir_, annual_reports_dir, str(file_id) + '.txt'), \"r\", encoding='utf-8') as report_file:\n",
    "            for line in report_file:\n",
    "                line = line.replace(\"\\n\", \"\").replace(\"\\t\", \" \").replace(\"\\xa0\", \" \")\n",
    "                tmp_file.append(line)\n",
    "        report_txt = \" \".join(tmp_file)\n",
    "        \n",
    "        # For Strings\n",
    "        parser = PlaintextParser.from_string(report_txt,Tokenizer(\"spanish\"))\n",
    "        # Summarize using sumy TextRank\n",
    "        summarizer = TextRankSummarizer()\n",
    "        summary =summarizer(parser.document,20)\n",
    "        text_summary=\"\"\n",
    "        for sentence in summary:\n",
    "            text_summary+=str(sentence)\n",
    "        summary_split = text_summary.split(' ')\n",
    "        number_of_words = len(summary_split)\n",
    "        print(number_of_words)\n",
    "        if number_of_words > 1000:\n",
    "            text_summary = \" \".join(summary_split[:1000])\n",
    "        \n",
    "        with open(os.path.join(text_rank_dir, file_id+'.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.write(str(text_summary))\n",
    "            \n",
    "        if \".DS_Store\" in file:\n",
    "            continue\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(file, e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e00e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_evaluation import get_rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc96647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File Number:  0\n",
      "local variable 'sum_scores' referenced before assignment\n",
      "Number of files processed:  0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zm/pvdw66f97v9cmg7tw8wq8jr40000gn/T/ipykernel_41007/2257227494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgold_summary_dir_\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_summary_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrouge_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rouge_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_rank_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_summary_dir_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrouge_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/FNP_2022/GitRepo/FNS2022/0_Baselines/rouge_evaluation.py\u001b[0m in \u001b[0;36mget_rouge_scores\u001b[0;34m(system_summary_dir, gold_summary_dir)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of files processed: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mrouge_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mrouge_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mrouge_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "gold_summary_dir_ =  os.path.join(dir_, gold_summary_dir)\n",
    "rouge_scores = get_rouge_scores(text_rank_dir, gold_summary_dir_)\n",
    "rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a76d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f0bce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(text_rank_dir, '276.txt'), \"r\", encoding='utf-8') as f:\n",
    "    system_summary_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6f873fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'p': 0.5333333333333333,\n",
       "  'r': 0.2840687797804019,\n",
       "  'f': 0.14021969243059718},\n",
       " 'rouge-2': {'p': 0.3389830508474576,\n",
       "  'r': 0.11864783226723524,\n",
       "  'f': 0.06329145129878135}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_rouge_scores = {}\n",
    "sum_rouge_scores['rouge-1'] = {}\n",
    "sum_rouge_scores['rouge-2'] = {}\n",
    "\n",
    "sum_rouge_scores['rouge-1']['p'] = 0\n",
    "sum_rouge_scores['rouge-1']['r'] = 0\n",
    "sum_rouge_scores['rouge-1']['f'] = 0\n",
    "sum_rouge_scores['rouge-2']['p'] = 0\n",
    "sum_rouge_scores['rouge-2']['r'] = 0\n",
    "sum_rouge_scores['rouge-2']['f'] = 0\n",
    "num_sum_file = 0\n",
    "file_id = '276'\n",
    "for sum_file in os.listdir(gold_summary_dir_):\n",
    "    if \".DS_Store\" in file:\n",
    "        continue\n",
    "    if os.path.isfile(os.path.join(gold_summary_dir_, sum_file)) and file_id == sum_file.split(\"_\")[0]:\n",
    "        with open(os.path.join(gold_summary_dir_, sum_file), \"r\", encoding='utf-8') as f:\n",
    "            gold_sum_txt = f.read()\n",
    "            sum_scores = scorer.score(gold_sum_txt, system_summary_txt)\n",
    "        sum_rouge_scores['rouge-1']['p'] = sum_rouge_scores['rouge-1']['p'] + sum_scores['rouge1'][0]\n",
    "        sum_rouge_scores['rouge-1']['r'] = sum_rouge_scores['rouge-1']['r'] + sum_scores['rouge1'][1]\n",
    "        sum_rouge_scores['rouge-1']['f'] = sum_rouge_scores['rouge-1']['f'] + sum_scores['rouge1'][2]\n",
    "        sum_rouge_scores['rouge-2']['p'] = sum_rouge_scores['rouge-2']['p'] + sum_scores['rouge2'][0]\n",
    "        sum_rouge_scores['rouge-2']['r'] = sum_rouge_scores['rouge-2']['r'] + sum_scores['rouge2'][1]\n",
    "        sum_rouge_scores['rouge-2']['f'] = sum_rouge_scores['rouge-2']['f'] + sum_scores['rouge2'][2]\n",
    "        num_sum_file = num_sum_file + 1\n",
    "print(num_sum_file)\n",
    "sum_rouge_scores['rouge-1']['p'] = sum_rouge_scores['rouge-1']['p'] / (num_sum_file)\n",
    "sum_rouge_scores['rouge-1']['r'] = sum_rouge_scores['rouge-1']['r'] / (num_sum_file)\n",
    "sum_rouge_scores['rouge-1']['f'] = sum_rouge_scores['rouge-1']['f'] / (num_sum_file)\n",
    "sum_rouge_scores['rouge-2']['p'] = sum_rouge_scores['rouge-2']['p'] / (num_sum_file)\n",
    "sum_rouge_scores['rouge-2']['r'] = sum_rouge_scores['rouge-2']['r'] / (num_sum_file)\n",
    "sum_rouge_scores['rouge-2']['f'] = sum_rouge_scores['rouge-2']['f'] / (num_sum_file)\n",
    "sum_rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36a2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(lex_rank_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca597c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File Number:  0 0007.txt\n",
      "1056\n",
      "Processing File Number:  1 0013.txt\n",
      "907\n",
      "Processing File Number:  2 0012.txt\n",
      "1006\n",
      "Processing File Number:  3 0006.txt\n"
     ]
    }
   ],
   "source": [
    "num_file = 0\n",
    "\n",
    "for file in os.listdir(os.path.join(dir_, annual_reports_dir)):\n",
    "    try:\n",
    "        print(\"Processing File Number: \", num_file, file)\n",
    "        num_file = num_file +1 \n",
    "        file_id = file.split('.')[0]\n",
    "        \n",
    "        tmp_file = []\n",
    "        with open(os.path.join(dir_, annual_reports_dir, str(file_id) + '.txt'), \"r\", encoding='utf-8') as report_file:\n",
    "            for line in report_file:\n",
    "                line = line.replace(\"\\n\", \"\").replace(\"\\t\", \" \").replace(\"\\xa0\", \" \")\n",
    "                tmp_file.append(line)\n",
    "        report_txt = \" \".join(tmp_file)\n",
    "        \n",
    "        # For Strings\n",
    "        parser = PlaintextParser.from_string(report_txt,Tokenizer(\"spanish\"))\n",
    "        # Summarize using sumy LexRank\n",
    "        summarizer = LexRankSummarizer()\n",
    "        summary =summarizer(parser.document,20)\n",
    "        text_summary=\"\"\n",
    "        for sentence in summary:\n",
    "            text_summary+=str(sentence)\n",
    "        summary_split = text_summary.split(' ')\n",
    "        number_of_words = len(summary_split)\n",
    "        print(number_of_words)\n",
    "        if number_of_words > 1000:\n",
    "            text_summary = \" \".join(summary_split[:1000])\n",
    "        \n",
    "        with open(os.path.join(lex_rank_dir, file_id+'.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.write(str(text_summary))\n",
    "            \n",
    "        if \".DS_Store\" in file:\n",
    "            continue\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(file, e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
